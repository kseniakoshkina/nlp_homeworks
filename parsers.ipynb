{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На последнем семинаре мы проанализировали несколько различных морфологических теггеров. Как же узнать, какой использовать? Давайте сравним их качество!\n",
    "В этой домашке вам будет нужно найти или самим написать русский и английский тексты (каждый от ста слов), в которых будут какие-то трудные или неоднозначные для POS теггинга моменты и разметить их в ручную (а потом объяснить, какие моменты вы тут считаете трудными для автоматического посттеггинга и почему) – с помощью этих текстов мы будем оценивать качество работы наших теггоров. В текстах размечаем только части речи, ничего больше!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Текст на русском: Прошлый уикэнд мы чиллили с корешами и хорошо погамали. Сосед купил новый телик, поэтому музон орал на весь дом. С недавних пор мой бро работает ментом. Я просрал раффл и завафлил познакомиться с сасной тянкой. Аутфиты были бомбезными: ичиги, багги, дебри, мартинсы. Потом мои братки поехали в бутик, но там было очень дорого, и они погуглили в инете и надыбали аутлет. Там они нашли какого-то коуча, который по фану их затроллил и предложил купить паленые сникеры. Я решил закрыть глаза на понты моих друзей, но они знатно до меня докапались. Не выкупаю, почему они все время надо мной рофлят. В итоге я не сдержался и сказал, что вся их обувь это галимая паль и они не имеют права называть себя сникерхэдами и хайпить на этом. Один чувак сказал, что они отвечают за свой спич. Но я давно уже выкупил, что моему корешу достается все по блату. Энивей, пати у нас прошла отстойно, мне обломали весь кайф."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Трудные слова: уикэнд(так как заимствованное и используется в речи с относительно недавних времен); чиллили (заимствованное, вообще новое); кореш (жаргонное); погамали (образовано от английского слова \"game\" - игра, заимствованное слово); телик - скорещенно от \"телевизор\"; музон - от \"музыка\"; мент - жаргонное; велик - сокращенно от \"велосипед\"; офигели - используется в речи и в соцсетях; тусоваться - жаргонное; девяностые - возможно сложно; аутфиты - заимствованное, ичиги, багги, дебри, мартинсы - заимствованные или редко используемые; бомбезный - жаргонное; понты - жаргонное; предки - жаргонное; чувак - жаргонное; спич - заимствованное; энивей - заимствованное; пати - заимствованное."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = {'прошлый':'ADJ', 'уикэнд':'NOUN','мы':'PRON', 'чиллили':'VERB','с':'PREP', 'корешами':'NOUN','и':'CONJ',\n",
    "         'хорошо':'ADV','погамали':'VERB','сосед':'NOUN','купил':'VERB','новый':'ADJ', 'телик':'NOUN','поэтому':'ADV', \n",
    "         'музон':'NOUN', 'орал':'VERB', 'на':'PREP','весь':'ADJ','дом':'NOUN','недавних':'ADJ','пор':'NOUN','мой':'APRO',\n",
    "         'бро':'NOUN', 'работает':'VERB', 'ментом':'NOUN', 'ездит':'VERB',  'работу':'NOUN', 'велике':'NOUN',\n",
    "         'туса':'NOUN','была': 'VERB','настолько': 'ADV','крейзи': 'ADJ','что': 'CONJ','мои': 'APRO','друзья': 'NOUN',\n",
    "         'офигели': 'VERB','будто': 'CONJ','тусовались': 'VERB','в': 'PREP','девяностых': 'NUM',\n",
    "         'я': 'PRON','просрал': 'VERB','раффл': 'NOUN','завафлил': 'VERB', 'познакомиться': 'INFN',\n",
    "         'сасной': 'ADJ','тянкой': 'NOUN','аутфиты': 'NOUN','были': 'VERB','бомбезными': 'ADJ','ичиги': 'NOUN','багги': 'NOUN',\n",
    "         'дебри': 'NOUN','мартинсы': 'NOUN','потом': 'ADV','братки': 'NOUN','поехали': 'VERB','бутик': 'NOUN','но': 'CONJ',\n",
    "         'там': 'ADV','было': 'VERB','очень': 'ADV','дорого': 'ADV','они': 'PRON','погуглили': 'VERB','инете': 'NOUN',\n",
    "         'надыбали': 'VERB','аутлет': 'NOUN','нашли': 'VERB','какого-то': 'ADJ','коуча': 'NOUN', 'который': 'ADJ','по': 'PREP',\n",
    "         'фану': 'NOUN','их': 'PRON','затроллил': 'VERB','предложил': 'VERB','купить': 'INFN','палёные': 'ADJ','сникеры': 'NOUN',\n",
    "         'решил': 'VERB','закрыть': 'INFN','глаза': 'NOUN','понты': 'NOUN','моих': 'APRO','друзей': 'NOUN','знатно': 'ADV',\n",
    "         'до': 'PREP','меня': 'PRON','докапались': 'VERB','не': 'PART','выкупаю': 'VERB','почему': 'ADV','все': 'ADJ',\n",
    "         'время': 'NOUN','надо': 'ADV','мной': 'PRON','рофлят': 'VERB','итоге': 'NOUN','сдержался': 'VERB','сказал': 'VERB',\n",
    "         'вся': 'ADJ','обувь': 'NOUN','это': 'PRCL','галимая': 'ADJ','паль': 'NOUN','имеют': 'VERB','права': 'NOUN','называть': 'INFN',\n",
    "         'себя': 'PRON','сникерхэдами': 'NOUN','хайпить': 'INFN','этом': 'PRON','один': 'NUM','чувак': 'NOUN','отвечают': 'VERB',\n",
    "         'за': 'PREP','свой': 'APRO','спич': 'NOUN','давно': 'ADV','уже': 'ADV','выкупил': 'VERB','моему': 'APRO','корешу': 'NOUN',\n",
    "         'достаётся': 'VERB','блату': 'NOUN','энивей': 'ADV','пати': 'NOUN','у': 'PREP','нас': 'PRON','прошла': 'VERB',\n",
    "         'отстойно': 'ADV','мне': 'PRON','обломали': 'VERB','кайф': 'NOUN'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "m = MorphAnalyzer()\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Прошлый уикэнд мы чиллили с корешами и хорошо погамали. Сосед купил новый телик, поэтому музон орал на весь дом. С недавних пор мой бро работает ментом и ездит на работу на велике. Туса была настолько крейзи, что мои друзья офигели. Мы будто тусовались в девяностых. Я просрал раффл и завафлил познакомиться с сасной тянкой. Аутфиты были бомбезными: ичиги, багги, дебри, мартинсы. Потом мои братки поехали в бутик, но там было очень дорого, и они погуглили в инете и надыбали аутлет. Там они нашли какого-то коуча, который по фану их затроллил и предложил купить паленые сникеры. Я решил закрыть глаза на понты моих друзей, но они знатно до меня докапались. Не выкупаю, почему они все время надо мной рофлят. В итоге я не сдержался и сказал, что вся их обувь это галимая паль и они не имеют права называть себя сникерхэдами и хайпить на этом. Один чувак сказал, что они отвечают за свой спич. Но я давно уже выкупил, что моему корешу достается все по блату. Энивей, пати у нас прошла отстойно, мне обломали весь кайф.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace ('.','')\n",
    "text = text.replace (',','')\n",
    "text = text.replace (':','')\n",
    "text = text.lower()\n",
    "parse_pymorphy = []\n",
    "parse_pymorphy_2 = []\n",
    "for token in text.split():\n",
    "    ana = m.parse(token)[0]\n",
    "    parse_pymorphy.append(ana.word)\n",
    "    parse_pymorphy_2.append(re.findall(r'[A-Z]{4}',str(ana.tag))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ADJF' in parse_pymorphy_2:\n",
    "    parse_pymorphy_2 = [*map({'ADJF': 'ADJ'}.get, parse_pymorphy_2, parse_pymorphy_2)]\n",
    "if 'NPRO' in parse_pymorphy_2:\n",
    "    parse_pymorphy_2 = [*map({'NPRO': 'PRON'}.get, parse_pymorphy_2, parse_pymorphy_2)]\n",
    "if 'ADVB' in parse_pymorphy_2:\n",
    "    parse_pymorphy_2 = [*map({'ADVB': 'ADV'}.get, parse_pymorphy_2, parse_pymorphy_2)]\n",
    "if 'PRCL' in parse_pymorphy_2:\n",
    "    parse_pymorphy_2 = [*map({'PRCL': 'PART'}.get, parse_pymorphy_2, parse_pymorphy_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_pymorphy_dict = dict(zip(parse_pymorphy,parse_pymorphy_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'прошлый': 'ADJ',\n",
       " 'уикэнд': 'NOUN',\n",
       " 'мы': 'PRON',\n",
       " 'чиллили': 'NOUN',\n",
       " 'с': 'PREP',\n",
       " 'корешами': 'NOUN',\n",
       " 'и': 'CONJ',\n",
       " 'хорошо': 'ADV',\n",
       " 'погамали': 'NOUN',\n",
       " 'сосед': 'NOUN',\n",
       " 'купил': 'VERB',\n",
       " 'новый': 'ADJ',\n",
       " 'телик': 'NOUN',\n",
       " 'поэтому': 'ADV',\n",
       " 'музон': 'NOUN',\n",
       " 'орал': 'NOUN',\n",
       " 'на': 'PREP',\n",
       " 'весь': 'ADJ',\n",
       " 'дом': 'NOUN',\n",
       " 'недавних': 'ADJ',\n",
       " 'пор': 'NOUN',\n",
       " 'мой': 'ADJ',\n",
       " 'бро': 'UNKN',\n",
       " 'работает': 'VERB',\n",
       " 'ментом': 'NOUN',\n",
       " 'ездит': 'VERB',\n",
       " 'работу': 'NOUN',\n",
       " 'велике': 'NOUN',\n",
       " 'туса': 'NOUN',\n",
       " 'была': 'VERB',\n",
       " 'настолько': 'ADV',\n",
       " 'крейзи': 'NOUN',\n",
       " 'что': 'CONJ',\n",
       " 'мои': 'ADJ',\n",
       " 'друзья': 'NOUN',\n",
       " 'офигели': 'NOUN',\n",
       " 'будто': 'CONJ',\n",
       " 'тусовались': 'VERB',\n",
       " 'в': 'PREP',\n",
       " 'девяностых': 'ADJ',\n",
       " 'я': 'PRON',\n",
       " 'просрал': 'NOUN',\n",
       " 'раффл': 'NOUN',\n",
       " 'завафлил': 'NOUN',\n",
       " 'познакомиться': 'INFN',\n",
       " 'сасной': 'NOUN',\n",
       " 'тянкой': 'NOUN',\n",
       " 'аутфиты': 'NOUN',\n",
       " 'были': 'VERB',\n",
       " 'бомбезными': 'ADJ',\n",
       " 'ичиги': 'NOUN',\n",
       " 'багги': 'NOUN',\n",
       " 'дебри': 'NOUN',\n",
       " 'мартинсы': 'NOUN',\n",
       " 'потом': 'ADV',\n",
       " 'братки': 'NOUN',\n",
       " 'поехали': 'VERB',\n",
       " 'бутик': 'NOUN',\n",
       " 'но': 'CONJ',\n",
       " 'там': 'ADV',\n",
       " 'было': 'VERB',\n",
       " 'очень': 'ADV',\n",
       " 'дорого': 'ADV',\n",
       " 'они': 'PRON',\n",
       " 'погуглили': 'NOUN',\n",
       " 'инете': 'VERB',\n",
       " 'надыбали': 'NOUN',\n",
       " 'аутлет': 'NOUN',\n",
       " 'нашли': 'VERB',\n",
       " 'какого-то': 'ADJ',\n",
       " 'коуча': 'GRND',\n",
       " 'который': 'ADJ',\n",
       " 'по': 'PREP',\n",
       " 'фану': 'NOUN',\n",
       " 'их': 'PRON',\n",
       " 'затроллил': 'NOUN',\n",
       " 'предложил': 'VERB',\n",
       " 'купить': 'INFN',\n",
       " 'палёные': 'ADJ',\n",
       " 'сникеры': 'NOUN',\n",
       " 'решил': 'VERB',\n",
       " 'закрыть': 'INFN',\n",
       " 'глаза': 'NOUN',\n",
       " 'понты': 'NOUN',\n",
       " 'моих': 'ADJ',\n",
       " 'друзей': 'NOUN',\n",
       " 'знатно': 'ADV',\n",
       " 'до': 'PREP',\n",
       " 'меня': 'PRON',\n",
       " 'докапались': 'VERB',\n",
       " 'не': 'PART',\n",
       " 'выкупаю': 'VERB',\n",
       " 'почему': 'ADV',\n",
       " 'все': 'ADJ',\n",
       " 'время': 'NOUN',\n",
       " 'надо': 'PRED',\n",
       " 'мной': 'PRON',\n",
       " 'рофлят': 'VERB',\n",
       " 'итоге': 'NOUN',\n",
       " 'сдержался': 'VERB',\n",
       " 'сказал': 'VERB',\n",
       " 'вся': 'ADJ',\n",
       " 'обувь': 'NOUN',\n",
       " 'это': 'PART',\n",
       " 'галимая': 'NOUN',\n",
       " 'паль': 'NOUN',\n",
       " 'имеют': 'VERB',\n",
       " 'права': 'NOUN',\n",
       " 'называть': 'INFN',\n",
       " 'себя': 'PRON',\n",
       " 'сникерхэдами': 'NOUN',\n",
       " 'хайпить': 'INFN',\n",
       " 'этом': 'PRON',\n",
       " 'один': 'ADJ',\n",
       " 'чувак': 'NOUN',\n",
       " 'отвечают': 'VERB',\n",
       " 'за': 'PREP',\n",
       " 'свой': 'ADJ',\n",
       " 'спич': 'NOUN',\n",
       " 'давно': 'ADV',\n",
       " 'уже': 'ADV',\n",
       " 'выкупил': 'VERB',\n",
       " 'моему': 'ADJ',\n",
       " 'корешу': 'NOUN',\n",
       " 'достаётся': 'VERB',\n",
       " 'блату': 'NOUN',\n",
       " 'энивей': 'VERB',\n",
       " 'пати': 'NOUN',\n",
       " 'у': 'PREP',\n",
       " 'нас': 'PRON',\n",
       " 'прошла': 'VERB',\n",
       " 'отстойно': 'ADJS',\n",
       " 'мне': 'PRON',\n",
       " 'обломали': 'VERB',\n",
       " 'кайф': 'NOUN'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_pymorphy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "m = Mystem()\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed_text = m.analyze(text)\n",
    "parse_mystem = {}\n",
    "data_1 = []\n",
    "data_2 = []\n",
    "for word in analyzed_text:\n",
    "    if 'analysis' in word:\n",
    "        gr = word['analysis'][0]['gr']\n",
    "        pos = gr.split('=')[0].split(',')[0]\n",
    "        data_1.append(word['text'])\n",
    "        data_2.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'A' in data_2:\n",
    "    data_2 = [*map({'A': 'ADJ'}.get, data_2, data_2)]\n",
    "if 'S' in data_2:\n",
    "    data_2 = [*map({'S': 'NOUN'}.get, data_2, data_2)]\n",
    "if 'ADVPRO' in data_2:\n",
    "    data_2 = [*map({'ADVPRO': 'ADV'}.get, data_2, data_2)]\n",
    "if 'PR' in data_2:\n",
    "    data_2 = [*map({'PR': 'PREP'}.get, data_2, data_2)]\n",
    "if 'V' in data_2:\n",
    "    data_2 = [*map({'V': 'VERB'}.get, data_2, data_2)]\n",
    "if 'APRO' in data_2:\n",
    "    data_2 = [*map({'APRO': 'ADJ'}.get, data_2, data_2)]\n",
    "if 'SPRO' in data_2:\n",
    "    data_2 = [*map({'SPRO': 'PRON'}.get, data_2, data_2)]\n",
    "if 'ANUM' in data_2:\n",
    "    data_2 = [*map({'ANUM': 'NUM'}.get, data_2, data_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_mystem_dict = dict(zip(data_1,data_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'прошлый': 'ADJ',\n",
       " 'уикэнд': 'NOUN',\n",
       " 'мы': 'PRON',\n",
       " 'чиллили': 'NOUN',\n",
       " 'с': 'PREP',\n",
       " 'корешами': 'NOUN',\n",
       " 'и': 'CONJ',\n",
       " 'хорошо': 'ADV',\n",
       " 'погамали': 'NOUN',\n",
       " 'сосед': 'NOUN',\n",
       " 'купил': 'VERB',\n",
       " 'новый': 'ADJ',\n",
       " 'телик': 'NOUN',\n",
       " 'поэтому': 'ADV',\n",
       " 'музон': 'NOUN',\n",
       " 'орал': 'VERB',\n",
       " 'на': 'PREP',\n",
       " 'весь': 'ADJ',\n",
       " 'дом': 'NOUN',\n",
       " 'недавних': 'ADJ',\n",
       " 'пор': 'NOUN',\n",
       " 'мой': 'ADJ',\n",
       " 'бро': 'NOUN',\n",
       " 'работает': 'VERB',\n",
       " 'ментом': 'NOUN',\n",
       " 'ездит': 'VERB',\n",
       " 'работу': 'NOUN',\n",
       " 'велике': 'NOUN',\n",
       " 'туса': 'NOUN',\n",
       " 'была': 'VERB',\n",
       " 'настолько': 'ADV',\n",
       " 'крейзи': 'NOUN',\n",
       " 'что': 'CONJ',\n",
       " 'мои': 'ADJ',\n",
       " 'друзья': 'NOUN',\n",
       " 'офигели': 'VERB',\n",
       " 'будто': 'CONJ',\n",
       " 'тусовались': 'VERB',\n",
       " 'в': 'PREP',\n",
       " 'девяностых': 'NUM',\n",
       " 'я': 'PRON',\n",
       " 'просрал': 'VERB',\n",
       " 'раффл': 'NOUN',\n",
       " 'завафлил': 'NOUN',\n",
       " 'познакомиться': 'VERB',\n",
       " 'сасной': 'ADJ',\n",
       " 'тянкой': 'NOUN',\n",
       " 'аутфиты': 'NOUN',\n",
       " 'были': 'VERB',\n",
       " 'бомбезными': 'ADJ',\n",
       " 'ичиги': 'NOUN',\n",
       " 'багги': 'NOUN',\n",
       " 'дебри': 'NOUN',\n",
       " 'мартинсы': 'NOUN',\n",
       " 'потом': 'ADV',\n",
       " 'братки': 'NOUN',\n",
       " 'поехали': 'VERB',\n",
       " 'бутик': 'NOUN',\n",
       " 'но': 'CONJ',\n",
       " 'там': 'ADV',\n",
       " 'было': 'VERB',\n",
       " 'очень': 'ADV',\n",
       " 'дорого': 'ADJ',\n",
       " 'они': 'PRON',\n",
       " 'погуглили': 'VERB',\n",
       " 'инете': 'NOUN',\n",
       " 'надыбали': 'VERB',\n",
       " 'аутлет': 'NOUN',\n",
       " 'нашли': 'VERB',\n",
       " 'какого-то': 'ADJ',\n",
       " 'коуча': 'NOUN',\n",
       " 'который': 'ADJ',\n",
       " 'по': 'PREP',\n",
       " 'фану': 'NOUN',\n",
       " 'их': 'ADJ',\n",
       " 'затроллил': 'NOUN',\n",
       " 'предложил': 'VERB',\n",
       " 'купить': 'VERB',\n",
       " 'паленые': 'ADJ',\n",
       " 'сникеры': 'NOUN',\n",
       " 'решил': 'VERB',\n",
       " 'закрыть': 'VERB',\n",
       " 'глаза': 'NOUN',\n",
       " 'понты': 'NOUN',\n",
       " 'моих': 'ADJ',\n",
       " 'друзей': 'NOUN',\n",
       " 'знатно': 'ADV',\n",
       " 'до': 'PREP',\n",
       " 'меня': 'PRON',\n",
       " 'докапались': 'VERB',\n",
       " 'не': 'PART',\n",
       " 'выкупаю': 'VERB',\n",
       " 'почему': 'ADV',\n",
       " 'все': 'PRON',\n",
       " 'время': 'NOUN',\n",
       " 'надо': 'ADV',\n",
       " 'мной': 'PRON',\n",
       " 'рофлят': 'NOUN',\n",
       " 'итоге': 'NOUN',\n",
       " 'сдержался': 'VERB',\n",
       " 'сказал': 'VERB',\n",
       " 'вся': 'ADJ',\n",
       " 'обувь': 'NOUN',\n",
       " 'это': 'PART',\n",
       " 'галимая': 'ADJ',\n",
       " 'паль': 'NOUN',\n",
       " 'имеют': 'VERB',\n",
       " 'права': 'NOUN',\n",
       " 'называть': 'VERB',\n",
       " 'себя': 'PRON',\n",
       " 'сникерхэдами': 'NOUN',\n",
       " 'хайпить': 'NOUN',\n",
       " 'этом': 'PRON',\n",
       " 'один': 'ADJ',\n",
       " 'чувак': 'NOUN',\n",
       " 'отвечают': 'VERB',\n",
       " 'за': 'PREP',\n",
       " 'свой': 'ADJ',\n",
       " 'спич': 'NOUN',\n",
       " 'давно': 'ADV',\n",
       " 'уже': 'ADV',\n",
       " 'выкупил': 'VERB',\n",
       " 'моему': 'ADJ',\n",
       " 'корешу': 'NOUN',\n",
       " 'достается': 'VERB',\n",
       " 'блату': 'NOUN',\n",
       " 'энивей': 'ADV',\n",
       " 'пати': 'NOUN',\n",
       " 'у': 'PREP',\n",
       " 'нас': 'PRON',\n",
       " 'прошла': 'VERB',\n",
       " 'отстойно': 'ADJ',\n",
       " 'мне': 'PRON',\n",
       " 'обломали': 'VERB',\n",
       " 'кайф': 'NOUN'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_mystem_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    \n",
    "    PER,\n",
    "    NamesExtractor,\n",
    "\n",
    "    Doc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = Segmenter()\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "syntax_parser = NewsSyntaxParser(emb)\n",
    "ner_tagger = NewsNERTagger(emb)\n",
    "morph_vocab = MorphVocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = Doc(text)\n",
    "doc.segment(segmenter)\n",
    "doc.tag_morph(morph_tagger)\n",
    "for token in doc.tokens:\n",
    "    token.lemmatize(morph_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_data_1 = []\n",
    "token_data_2 = []\n",
    "for k in doc.tokens:\n",
    "    token_data_1.append(re.findall(r'text=\\S[А-Яа-я]+\\S',str(k)))\n",
    "    token_data_2.append(re.findall(r'pos=\\S[A-Za-z]+\\S',str(k)))\n",
    "re_data_1 = []\n",
    "re_data_2 = []\n",
    "for k in token_data_1:\n",
    "    re_data_1.append(re.findall(r'[А-Яа-я]+',k[0])[0])\n",
    "for k in token_data_2:\n",
    "    re_data_2.append(re.findall(r'[A-Z]+',k[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'CCONJ' in re_data_2:\n",
    "    re_data_2 = [*map({'CCONJ': 'CONJ'}.get, re_data_2, re_data_2)]\n",
    "if 'ADP' in re_data_2:\n",
    "    re_data_2 = [*map({'ADP': 'PREP'}.get, re_data_2, re_data_2)]\n",
    "if 'DET' in re_data_2:\n",
    "    re_data_2 = [*map({'DET': 'ADJ'}.get, re_data_2, re_data_2)]\n",
    "if 'APRO' in re_data_2:\n",
    "    re_data_2 = [*map({'APRO': 'ADJ'}.get, re_data_2, re_data_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_natasha = {}\n",
    "l = 0\n",
    "\n",
    "while l != len(re_data_1):\n",
    "    parse_natasha[re_data_1[l]]=re_data_2[l]\n",
    "    l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'прошлый': 'ADJ',\n",
       " 'уикэнд': 'NOUN',\n",
       " 'мы': 'PRON',\n",
       " 'чиллили': 'VERB',\n",
       " 'с': 'PREP',\n",
       " 'корешами': 'NOUN',\n",
       " 'и': 'CONJ',\n",
       " 'хорошо': 'ADV',\n",
       " 'погамали': 'ADJ',\n",
       " 'сосед': 'NOUN',\n",
       " 'купил': 'VERB',\n",
       " 'новый': 'ADJ',\n",
       " 'телик': 'NOUN',\n",
       " 'поэтому': 'ADV',\n",
       " 'музон': 'ADV',\n",
       " 'орал': 'VERB',\n",
       " 'на': 'PREP',\n",
       " 'весь': 'ADJ',\n",
       " 'дом': 'NOUN',\n",
       " 'недавних': 'ADJ',\n",
       " 'пор': 'NOUN',\n",
       " 'мой': 'ADJ',\n",
       " 'бро': 'NOUN',\n",
       " 'работает': 'VERB',\n",
       " 'ментом': 'NOUN',\n",
       " 'ездит': 'VERB',\n",
       " 'работу': 'NOUN',\n",
       " 'велике': 'NOUN',\n",
       " 'туса': 'NOUN',\n",
       " 'была': 'AUX',\n",
       " 'настолько': 'ADV',\n",
       " 'крейзи': 'ADJ',\n",
       " 'что': 'SCONJ',\n",
       " 'мои': 'ADJ',\n",
       " 'друзья': 'NOUN',\n",
       " 'офигели': 'VERB',\n",
       " 'будто': 'PART',\n",
       " 'тусовались': 'VERB',\n",
       " 'в': 'PREP',\n",
       " 'девяностых': 'ADJ',\n",
       " 'я': 'PRON',\n",
       " 'просрал': 'VERB',\n",
       " 'раффл': 'NOUN',\n",
       " 'завафлил': 'NOUN',\n",
       " 'познакомиться': 'VERB',\n",
       " 'сасной': 'ADJ',\n",
       " 'тянкой': 'ADJ',\n",
       " 'аутфиты': 'NOUN',\n",
       " 'были': 'AUX',\n",
       " 'бомбезными': 'VERB',\n",
       " 'ичиги': 'ADJ',\n",
       " 'багги': 'ADJ',\n",
       " 'дебри': 'NOUN',\n",
       " 'мартинсы': 'VERB',\n",
       " 'потом': 'ADV',\n",
       " 'братки': 'NOUN',\n",
       " 'поехали': 'VERB',\n",
       " 'бутик': 'NOUN',\n",
       " 'но': 'CONJ',\n",
       " 'там': 'ADV',\n",
       " 'было': 'AUX',\n",
       " 'очень': 'ADV',\n",
       " 'дорого': 'ADJ',\n",
       " 'они': 'PRON',\n",
       " 'погуглили': 'VERB',\n",
       " 'инете': 'NOUN',\n",
       " 'надыбали': 'ADJ',\n",
       " 'аутлет': 'NOUN',\n",
       " 'нашли': 'VERB',\n",
       " 'какого': 'ADJ',\n",
       " 'коуча': 'NOUN',\n",
       " 'который': 'PRON',\n",
       " 'по': 'PREP',\n",
       " 'фану': 'NOUN',\n",
       " 'их': 'ADJ',\n",
       " 'затроллил': 'NOUN',\n",
       " 'предложил': 'VERB',\n",
       " 'купить': 'VERB',\n",
       " 'паленые': 'ADJ',\n",
       " 'сникеры': 'NOUN',\n",
       " 'решил': 'VERB',\n",
       " 'закрыть': 'VERB',\n",
       " 'глаза': 'NOUN',\n",
       " 'понты': 'NOUN',\n",
       " 'моих': 'ADJ',\n",
       " 'друзей': 'NOUN',\n",
       " 'знатно': 'VERB',\n",
       " 'до': 'PREP',\n",
       " 'меня': 'PRON',\n",
       " 'докапались': 'VERB',\n",
       " 'не': 'PART',\n",
       " 'выкупаю': 'VERB',\n",
       " 'почему': 'ADV',\n",
       " 'все': 'PRON',\n",
       " 'время': 'NOUN',\n",
       " 'надо': 'PREP',\n",
       " 'мной': 'PRON',\n",
       " 'рофлят': 'NOUN',\n",
       " 'итоге': 'NOUN',\n",
       " 'сдержался': 'VERB',\n",
       " 'сказал': 'VERB',\n",
       " 'вся': 'ADJ',\n",
       " 'обувь': 'NOUN',\n",
       " 'это': 'PRON',\n",
       " 'галимая': 'ADJ',\n",
       " 'паль': 'NOUN',\n",
       " 'имеют': 'VERB',\n",
       " 'права': 'NOUN',\n",
       " 'называть': 'VERB',\n",
       " 'себя': 'PRON',\n",
       " 'сникерхэдами': 'ADJ',\n",
       " 'хайпить': 'VERB',\n",
       " 'этом': 'PRON',\n",
       " 'один': 'ADJ',\n",
       " 'чувак': 'NOUN',\n",
       " 'отвечают': 'VERB',\n",
       " 'за': 'PREP',\n",
       " 'свой': 'ADJ',\n",
       " 'спич': 'NOUN',\n",
       " 'давно': 'ADV',\n",
       " 'уже': 'ADV',\n",
       " 'выкупил': 'VERB',\n",
       " 'моему': 'ADJ',\n",
       " 'корешу': 'NOUN',\n",
       " 'достается': 'VERB',\n",
       " 'блату': 'NOUN',\n",
       " 'энивей': 'ADJ',\n",
       " 'пати': 'NOUN',\n",
       " 'у': 'PREP',\n",
       " 'нас': 'PRON',\n",
       " 'прошла': 'VERB',\n",
       " 'отстойно': 'ADJ',\n",
       " 'мне': 'PRON',\n",
       " 'обломали': 'VERB',\n",
       " 'кайф': 'NOUN'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_natasha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что у всех парсеров возникают проблемы с некоторыми \"современными\" словами. Mystem и Natasha справляются лучше, чем Pymorphy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Текст на английском: I know he failed the test, but you’ve got to give him props for trying.Kudos for organising this party. It’s brilliant! Robert aced his physics exam! She’s blatantly very annoyed, everyone can see it apart from you. Blimey, look at all this mess here! I’d only left the house for an hour, and look what you’ve done! He just botched it up, and it still leaks every time it rains! We had a lovely chin wag together, like the good old days.I was chuffed to bits! I only had three days to cram for it! Crikey! Have you spent all of our savings? Stop faffing around, we’re going to be late! I managed to flog my car for a really good price! I’ve been really ill for the past fortnight, and still haven’t recovered.I thought I was going to fail, I’m completely gobsmacked! I’m so gutted I failed my driving test, again! I should jolly well think so! She’s telling porkies. Don’t be so stroppy! I can eat my dinner at this table. It’s wonky! I made a perfect internest at the balcony. No way! She zumpеd you? I am wearing a shirt as my upperwear while at the same time I am sitting in jogging pants.Their goalkeeper was slaying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В тексте в основном молодежный слэнг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'I know he failed the test, but you’ve got to give him props for trying Kudos for organising this party. It’s brilliant! Robert aced his physics exam! She’s blatantly very annoyed, everyone can see it apart from you. Blimey, look at all this mess here! I’d only left the house for an hour, and look what you’ve done! He just botched it up, and it still leaks every time it rains! We had a lovely chin wag together, like the good old days.I was chuffed to bits! I only had three days to cram for it! Crikey! Have you spent all of our savings? Stop faffing around, we’re going to be late! I managed to flog my car for a really good price! I’ve been really ill for the past fortnight, and still haven’t recovered.I thought I was going to fail, I’m completely gobsmacked! I’m so gutted I failed my driving test, again! I should jolly well think so! She’s telling porkies. Don’t be so stroppy! I can eat my dinner at this table. It’s wonky! I made a perfect internest at the balcony. No way! She zumpеd you? I am wearing a shirt as my upperwear while at the same time I am sitting in jogging pants.Their goalkeeper was slaying.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_english = {'i': 'PRON','know': 'VERB','he': 'PRON','failed': 'VERB','the': 'DET','test': 'NOUN','but': 'CCONJ',\n",
    "                 'you': 'PRON','’ve': 'VERB','got': 'VERB','to': 'TO','give': 'VERB','him': 'PRON','props': 'NOUN',\n",
    "                 'for': 'ADP','trying': 'VERB','kudos': 'NOUN','organising': 'VERB','this': 'DET','party': 'NOUN',\n",
    "                 'it': 'PRON','’s': 'VERB','brilliant': 'ADJ','robert': 'PROPN','aced': 'VERB','his': 'DET','physics': 'NOUN',\n",
    "                 'exam': 'NOUN','she': 'PRON','blatantly': 'ADV','very': 'ADV','annoyed': 'ADJ','everyone': 'PRON',\n",
    "                 'can': 'VERB','see': 'VERB','apart': 'ADV','from': 'ADP','blimey': 'ADV','look': 'VERB','at': 'ADP',\n",
    "                 'all': 'DET','mess': 'NOUN','here': 'ADV','’d': 'AUX','only': 'ADV','left': 'VERB','house': 'NOUN','an': 'DET',\n",
    "                 'hour': 'NOUN','and': 'CCONJ','what': 'PRON','done': 'VERB','just': 'ADV','botched': 'VERB','up': 'ADV',\n",
    "                 'still': 'ADV','leaks': 'VERB','every': 'ADJ', 'time': 'NOUN','rains': 'VERB','we': 'PRON','had': 'VERB',\n",
    "                 'a': 'DET','lovely': 'ADJ','chin': 'NOUN','wag': 'NOUN','together': 'ADV','like': 'ADV','good': 'ADJ',\n",
    "                 'old': 'ADJ','days': 'NOUN','was': 'AUX','chuffed': 'VERB','bits': 'NOUN','three': 'NUM','cram': 'VERB',\n",
    "                 'crikey': 'ADV','have': 'AUX','spent': 'VERB','of': 'ADP','our': 'DET','savings': 'NOUN','stop': 'VERB',\n",
    "                 'faffing': 'VERB','around': 'ADV','’re': 'AUX','going': 'VERB','be': 'AUX','late': 'ADV','managed': 'VERB',\n",
    "                 'flog': 'VERB','my': 'DET','car': 'NOUN','really': 'ADV','price': 'NOUN','been': 'AUX','ill': 'ADJ','past': 'ADJ',\n",
    "                 'fortnight': 'NOUN','n’t': 'AUX','recovered': 'VERB','thought': 'VERB','fail': 'VERB','’m':'AUX','completely': 'ADV',\n",
    "                 'gobsmacked': 'VERB','so': 'ADV','gutted': 'VERB','driving': 'NOUN','again': 'ADV','should': 'VERB','jolly': 'ADV',\n",
    "                 'well': 'ADV','think': 'VERB','telling': 'VERB','porkies': 'NOUN','do': 'AUX','stroppy': 'ADJ',\n",
    "                 'eat': 'VERB','dinner': 'NOUN','table': 'NOUN','wonky': 'ADJ','made': 'VERB','perfect': 'ADJ','internest': 'NOUN',\n",
    "                 'balcony': 'NOUN','no': 'DET','way': 'NOUN','zumpеd': 'VERB','am': 'AUX','wearing': 'VERB','shirt': 'NOUN',\n",
    "                 'as': 'ADV','upperwear': 'NOUN','while': 'ADV','same': 'ADJ','sitting': 'VERB','in': 'ADP','jogging': 'VERB',\n",
    "                 'pants': 'NOUN','their': 'DET','goalkeeper': 'NOUN','slaying': 'VERB'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace ('.',' ')\n",
    "text = text.replace (',',' ')\n",
    "text = text.replace (':',' ')\n",
    "text = text.replace ('!',' ')\n",
    "text = text.replace ('?',' ')\n",
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package webtext to /Users/ico/nltk_data...\n",
      "[nltk_data]   Package webtext is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/ico/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('webtext')\n",
    "from nltk.corpus import webtext\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "ps = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "split_regex = re.compile(r'[.|!|?|…]')\n",
    "sentences = filter(lambda t: t, [t.strip() for t in split_regex.split(text)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_data = []\n",
    "for sentence in sentences:  \n",
    "    english_data.append(nltk.pos_tag(nltk.word_tokenize(sentence)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_nltk = {}\n",
    "nltk_data_1 = []\n",
    "nltk_data_2 = []\n",
    "for k in english_data:\n",
    "    for j in k:\n",
    "        nltk_data_1.append(j[0])\n",
    "        nltk_data_2.append(j[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleted(parser):\n",
    "    if 'NN' in parser:\n",
    "        parser = [*map({'NN': 'NOUN'}.get, parser,parser)]\n",
    "    if 'VBP' in parser:\n",
    "        parser = [*map({'VBP': 'VERB'}.get,parser,parser)]\n",
    "    if 'VBD' in parser:\n",
    "        parser = [*map({'VBD': 'VERB'}.get,parser,parser)]\n",
    "    if 'DT' in parser:\n",
    "        parser = [*map({'DT': 'DET'}.get,parser,parser)]\n",
    "    if 'CC' in parser:\n",
    "        parser = [*map({'CC': 'CCONJ'}.get,parser,parser)]\n",
    "    if 'PRP' in parser:\n",
    "        parser = [*map({'PRP': 'PRON'}.get,parser,parser)]\n",
    "    if 'JJ' in parser:\n",
    "        parser = [*map({'JJ': 'ADJ'}.get,parser,parser)]\n",
    "    if 'VB' in parser:\n",
    "        parser = [*map({'VB': 'VERB'}.get,parser,parser)]\n",
    "    if 'IN' in parser:\n",
    "        parser = [*map({'IN': 'ADP'}.get,parser,parser)]\n",
    "    if 'RB' in parser:\n",
    "        parser = [*map({'RB': 'ADV'}.get,parser,parser)]\n",
    "    if 'NNS' in parser:\n",
    "        parser = [*map({'NNS': 'NOUN'}.get,parser,parser)]\n",
    "    if 'MD' in parser:\n",
    "        parser = [*map({'MD': 'VERB'}.get,parser,parser)]\n",
    "    if 'RP' in parser:\n",
    "        parser = [*map({'RP': 'ADV'}.get,parser,parser)]\n",
    "    if 'VBZ' in parser:\n",
    "        parser = [*map({'VBZ': 'VERB'}.get,parser,parser)]\n",
    "    if 'WP' in parser:\n",
    "        parser = [*map({'WP': 'PRON'}.get,parser,parser)]\n",
    "    if 'PRP$' in parser:\n",
    "        parser = [*map({'PRP$': 'DET'}.get,parser,parser)]\n",
    "    if 'CD' in parser:\n",
    "        parser = [*map({'CD': 'NUM'}.get,parser,parser)]\n",
    "    if 'VBN' in parser:\n",
    "        parser = [*map({'VBN': 'VERB'}.get,parser,parser)]\n",
    "    if 'VBG' in parser:\n",
    "        parser = [*map({'VBG': 'VERB'}.get,parser,parser)]\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_data_2 = deleted(nltk_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_nltk = dict(zip(nltk_data_1,nltk_data_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 'NOUN',\n",
       " 'know': 'VERB',\n",
       " 'he': 'PRON',\n",
       " 'failed': 'VERB',\n",
       " 'the': 'DET',\n",
       " 'test': 'NOUN',\n",
       " 'but': 'CCONJ',\n",
       " 'you': 'PRON',\n",
       " '’': 'VERB',\n",
       " 've': 'ADV',\n",
       " 'got': 'VERB',\n",
       " 'to': 'TO',\n",
       " 'give': 'VERB',\n",
       " 'him': 'PRON',\n",
       " 'props': 'VERB',\n",
       " 'for': 'ADP',\n",
       " 'trying': 'VERB',\n",
       " 'kudos': 'NOUN',\n",
       " 'organising': 'VERB',\n",
       " 'this': 'DET',\n",
       " 'party': 'NOUN',\n",
       " 'it': 'PRON',\n",
       " 's': 'ADJ',\n",
       " 'brilliant': 'NOUN',\n",
       " 'robert': 'NOUN',\n",
       " 'aced': 'VERB',\n",
       " 'his': 'DET',\n",
       " 'physics': 'NOUN',\n",
       " 'exam': 'VERB',\n",
       " 'she': 'PRON',\n",
       " 'blatantly': 'ADV',\n",
       " 'very': 'ADV',\n",
       " 'annoyed': 'ADJ',\n",
       " 'everyone': 'NOUN',\n",
       " 'can': 'VERB',\n",
       " 'see': 'VERB',\n",
       " 'apart': 'ADV',\n",
       " 'from': 'ADP',\n",
       " 'blimey': 'VERB',\n",
       " 'look': 'VERB',\n",
       " 'at': 'ADP',\n",
       " 'all': 'DET',\n",
       " 'mess': 'NOUN',\n",
       " 'here': 'ADV',\n",
       " 'd': 'NOUN',\n",
       " 'only': 'ADV',\n",
       " 'left': 'VERB',\n",
       " 'house': 'NOUN',\n",
       " 'an': 'DET',\n",
       " 'hour': 'NOUN',\n",
       " 'and': 'CCONJ',\n",
       " 'what': 'PRON',\n",
       " 'done': 'VERB',\n",
       " 'just': 'ADV',\n",
       " 'botched': 'VERB',\n",
       " 'up': 'ADV',\n",
       " 'still': 'ADV',\n",
       " 'leaks': 'VERB',\n",
       " 'every': 'DET',\n",
       " 'time': 'NOUN',\n",
       " 'rains': 'VERB',\n",
       " 'we': 'PRON',\n",
       " 'had': 'VERB',\n",
       " 'a': 'DET',\n",
       " 'lovely': 'ADV',\n",
       " 'chin': 'ADJ',\n",
       " 'wag': 'VERB',\n",
       " 'together': 'ADV',\n",
       " 'like': 'ADP',\n",
       " 'good': 'ADJ',\n",
       " 'old': 'ADJ',\n",
       " 'days': 'NOUN',\n",
       " 'was': 'VERB',\n",
       " 'chuffed': 'VERB',\n",
       " 'bits': 'NOUN',\n",
       " 'three': 'NUM',\n",
       " 'cram': 'VERB',\n",
       " 'crikey': 'VERB',\n",
       " 'have': 'VERB',\n",
       " 'spent': 'VERB',\n",
       " 'of': 'ADP',\n",
       " 'our': 'DET',\n",
       " 'savings': 'NOUN',\n",
       " 'stop': 'VERB',\n",
       " 'faffing': 'VERB',\n",
       " 'around': 'ADP',\n",
       " 're': 'ADV',\n",
       " 'going': 'VERB',\n",
       " 'be': 'VERB',\n",
       " 'late': 'ADJ',\n",
       " 'managed': 'VERB',\n",
       " 'flog': 'VERB',\n",
       " 'my': 'DET',\n",
       " 'car': 'NOUN',\n",
       " 'really': 'ADV',\n",
       " 'price': 'NOUN',\n",
       " 'been': 'VERB',\n",
       " 'ill': 'VERB',\n",
       " 'past': 'ADJ',\n",
       " 'fortnight': 'NOUN',\n",
       " 'haven': 'VERB',\n",
       " 't': 'NOUN',\n",
       " 'recovered': 'VERB',\n",
       " 'thought': 'VERB',\n",
       " 'fail': 'VERB',\n",
       " 'm': 'NOUN',\n",
       " 'completely': 'ADV',\n",
       " 'gobsmacked': 'VERB',\n",
       " 'so': 'ADV',\n",
       " 'gutted': 'VERB',\n",
       " 'driving': 'ADJ',\n",
       " 'again': 'ADV',\n",
       " 'should': 'VERB',\n",
       " 'jolly': 'ADV',\n",
       " 'well': 'ADV',\n",
       " 'think': 'VERB',\n",
       " 'telling': 'VERB',\n",
       " 'porkies': 'NOUN',\n",
       " 'don': 'VERB',\n",
       " 'stroppy': 'ADJ',\n",
       " 'eat': 'VERB',\n",
       " 'dinner': 'NOUN',\n",
       " 'table': 'NOUN',\n",
       " 'wonky': 'NOUN',\n",
       " 'made': 'VERB',\n",
       " 'perfect': 'ADJ',\n",
       " 'internest': 'NOUN',\n",
       " 'balcony': 'NOUN',\n",
       " 'no': 'DET',\n",
       " 'way': 'NOUN',\n",
       " 'zumpеd': 'ADP',\n",
       " 'am': 'VERB',\n",
       " 'wearing': 'VERB',\n",
       " 'shirt': 'NOUN',\n",
       " 'as': 'ADP',\n",
       " 'upperwear': 'ADJ',\n",
       " 'while': 'NOUN',\n",
       " 'same': 'ADJ',\n",
       " 'sitting': 'VERB',\n",
       " 'in': 'ADP',\n",
       " 'jogging': 'VERB',\n",
       " 'pants': 'NOUN',\n",
       " 'their': 'DET',\n",
       " 'goalkeeper': 'NOUN',\n",
       " 'slaying': 'VERB'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "spacy_data_1 = []\n",
    "spacy_data_2 = []\n",
    "for i, s in enumerate(doc.sents):\n",
    "    for t in s:\n",
    "        spacy_data_1.append(t.text)\n",
    "        spacy_data_2.append(t.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'CCONJ' in spacy_data_2:\n",
    "    spacy_data_2 = [*map({'CCONJ': 'CONJ'}.get, spacy_data_2, spacy_data_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_spacy_dict = dict(zip(spacy_data_1,spacy_data_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SPACE'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_spacy_dict.pop(\" \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 'PRON',\n",
       " 'know': 'VERB',\n",
       " 'he': 'PRON',\n",
       " 'failed': 'VERB',\n",
       " 'the': 'DET',\n",
       " 'test': 'NOUN',\n",
       " 'but': 'CONJ',\n",
       " 'you': 'PRON',\n",
       " '’ve': 'VERB',\n",
       " 'got': 'VERB',\n",
       " 'to': 'PART',\n",
       " 'give': 'VERB',\n",
       " 'him': 'PRON',\n",
       " 'props': 'NOUN',\n",
       " 'for': 'ADP',\n",
       " 'trying': 'VERB',\n",
       " 'kudos': 'NOUN',\n",
       " 'organising': 'VERB',\n",
       " 'this': 'DET',\n",
       " 'party': 'NOUN',\n",
       " 'it': 'PRON',\n",
       " '’s': 'VERB',\n",
       " 'brilliant': 'ADJ',\n",
       " 'robert': 'PROPN',\n",
       " 'aced': 'VERB',\n",
       " 'his': 'DET',\n",
       " 'physics': 'NOUN',\n",
       " 'exam': 'NOUN',\n",
       " 'she': 'PRON',\n",
       " 'blatantly': 'ADV',\n",
       " 'very': 'ADV',\n",
       " 'annoyed': 'ADJ',\n",
       " 'everyone': 'PRON',\n",
       " 'can': 'VERB',\n",
       " 'see': 'VERB',\n",
       " 'apart': 'ADV',\n",
       " 'from': 'ADP',\n",
       " 'blimey': 'PROPN',\n",
       " 'look': 'VERB',\n",
       " 'at': 'ADP',\n",
       " 'all': 'DET',\n",
       " 'mess': 'NOUN',\n",
       " 'here': 'ADV',\n",
       " '’d': 'VERB',\n",
       " 'only': 'ADV',\n",
       " 'left': 'VERB',\n",
       " 'house': 'NOUN',\n",
       " 'an': 'DET',\n",
       " 'hour': 'NOUN',\n",
       " 'and': 'CONJ',\n",
       " 'what': 'PRON',\n",
       " 'done': 'VERB',\n",
       " 'just': 'ADV',\n",
       " 'botched': 'VERB',\n",
       " 'up': 'ADP',\n",
       " 'still': 'ADV',\n",
       " 'leaks': 'VERB',\n",
       " 'every': 'DET',\n",
       " 'time': 'NOUN',\n",
       " 'rains': 'VERB',\n",
       " 'we': 'PRON',\n",
       " 'had': 'AUX',\n",
       " 'a': 'DET',\n",
       " 'lovely': 'ADJ',\n",
       " 'chin': 'NOUN',\n",
       " 'wag': 'NOUN',\n",
       " 'together': 'ADV',\n",
       " 'like': 'SCONJ',\n",
       " 'good': 'ADJ',\n",
       " 'old': 'ADJ',\n",
       " 'days': 'NOUN',\n",
       " 'was': 'AUX',\n",
       " 'chuffed': 'VERB',\n",
       " 'bits': 'NOUN',\n",
       " 'three': 'NUM',\n",
       " 'cram': 'VERB',\n",
       " 'crikey': 'NOUN',\n",
       " 'have': 'AUX',\n",
       " 'spent': 'VERB',\n",
       " 'of': 'ADP',\n",
       " 'our': 'DET',\n",
       " 'savings': 'NOUN',\n",
       " 'stop': 'VERB',\n",
       " 'faffing': 'VERB',\n",
       " 'around': 'ADV',\n",
       " '’re': 'VERB',\n",
       " 'going': 'VERB',\n",
       " 'be': 'AUX',\n",
       " 'late': 'ADJ',\n",
       " 'managed': 'VERB',\n",
       " 'flog': 'VERB',\n",
       " 'my': 'DET',\n",
       " 'car': 'NOUN',\n",
       " 'really': 'ADV',\n",
       " 'price': 'NOUN',\n",
       " 'been': 'AUX',\n",
       " 'ill': 'ADJ',\n",
       " 'past': 'ADJ',\n",
       " 'fortnight': 'NOUN',\n",
       " 'n’t': 'PART',\n",
       " 'recovered': 'VERB',\n",
       " 'thought': 'VERB',\n",
       " 'fail': 'VERB',\n",
       " '’m': 'VERB',\n",
       " 'completely': 'ADV',\n",
       " 'gobsmacked': 'VERB',\n",
       " 'so': 'ADV',\n",
       " 'gutted': 'VERB',\n",
       " 'driving': 'NOUN',\n",
       " 'again': 'ADV',\n",
       " 'should': 'VERB',\n",
       " 'jolly': 'ADV',\n",
       " 'well': 'ADV',\n",
       " 'think': 'VERB',\n",
       " 'telling': 'VERB',\n",
       " 'porkies': 'NOUN',\n",
       " 'do': 'AUX',\n",
       " 'stroppy': 'ADJ',\n",
       " 'eat': 'VERB',\n",
       " 'dinner': 'NOUN',\n",
       " 'table': 'NOUN',\n",
       " 'wonky': 'ADJ',\n",
       " 'made': 'VERB',\n",
       " 'perfect': 'ADJ',\n",
       " 'internest': 'ADJ',\n",
       " 'balcony': 'NOUN',\n",
       " 'no': 'DET',\n",
       " 'way': 'NOUN',\n",
       " 'zumpеd': 'VERB',\n",
       " 'am': 'AUX',\n",
       " 'wearing': 'VERB',\n",
       " 'shirt': 'NOUN',\n",
       " 'as': 'SCONJ',\n",
       " 'upperwear': 'ADJ',\n",
       " 'while': 'NOUN',\n",
       " 'same': 'ADJ',\n",
       " 'sitting': 'VERB',\n",
       " 'in': 'ADP',\n",
       " 'jogging': 'VERB',\n",
       " 'pants': 'NOUN',\n",
       " 'their': 'DET',\n",
       " 'goalkeeper': 'NOUN',\n",
       " 'slaying': 'VERB'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_spacy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-05 16:09:00,420 loading file /Users/ico/.flair/models/en-pos-ontonotes-v0.5.pt\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "tagger = SequenceTagger.load('pos')\n",
    "sentence = Sentence(text)\n",
    "tagger.predict(sentence)\n",
    "\n",
    "k = sentence.to_tagged_string()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair_words = []\n",
    "flair_parse = []\n",
    "flair_words.append(re.findall(r'\\S{0,2}[a-z]+\\S{0,2}',k))\n",
    "flair_parse.append(re.findall(r'[A-Z]{1,4}',k))\n",
    "flair_words = flair_words[0]\n",
    "flair_parse = flair_parse[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair_parse = deleted(flair_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_flair = dict(zip(flair_words,flair_parse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 'PRON',\n",
       " 'know': 'VERB',\n",
       " 'he': 'PRON',\n",
       " 'failed': 'VERB',\n",
       " 'the': 'DET',\n",
       " 'test': 'NOUN',\n",
       " 'but': 'CCONJ',\n",
       " 'you': 'PRON',\n",
       " '’ve': 'VERB',\n",
       " 'got': 'VERB',\n",
       " 'to': 'TO',\n",
       " 'give': 'VERB',\n",
       " 'him': 'PRON',\n",
       " 'props': 'NOUN',\n",
       " 'for': 'ADP',\n",
       " 'trying': 'VERB',\n",
       " 'kudos': 'NOUN',\n",
       " 'organising': 'VERB',\n",
       " 'this': 'DET',\n",
       " 'party': 'NOUN',\n",
       " 'it': 'PRON',\n",
       " '’s': 'VERB',\n",
       " 'brilliant': 'ADJ',\n",
       " 'robert': 'NOUN',\n",
       " 'aced': 'VERB',\n",
       " 'his': 'PRON',\n",
       " 'physics': 'NOUN',\n",
       " 'exam': 'NOUN',\n",
       " 'she': 'PRON',\n",
       " 'blatantly': 'ADV',\n",
       " 'very': 'ADV',\n",
       " 'annoyed': 'ADJ',\n",
       " 'everyone': 'NOUN',\n",
       " 'can': 'VERB',\n",
       " 'see': 'VERB',\n",
       " 'apart': 'ADV',\n",
       " 'from': 'ADP',\n",
       " 'blimey': 'ADJ',\n",
       " 'look': 'VERB',\n",
       " 'at': 'ADP',\n",
       " 'all': 'DET',\n",
       " 'mess': 'NOUN',\n",
       " 'here': 'ADV',\n",
       " '’d': 'VERB',\n",
       " 'only': 'ADV',\n",
       " 'left': 'VERB',\n",
       " 'house': 'NOUN',\n",
       " 'an': 'DET',\n",
       " 'hour': 'NOUN',\n",
       " 'and': 'CCONJ',\n",
       " 'what': 'PRON',\n",
       " 'done': 'VERB',\n",
       " 'just': 'ADV',\n",
       " 'botched': 'VERB',\n",
       " 'up': 'ADV',\n",
       " 'still': 'ADV',\n",
       " 'leaks': 'VERB',\n",
       " 'every': 'DET',\n",
       " 'time': 'NOUN',\n",
       " 'rains': 'VERB',\n",
       " 'we': 'PRON',\n",
       " 'had': 'VERB',\n",
       " 'a': 'DET',\n",
       " 'lovely': 'ADJ',\n",
       " 'chin': 'NOUN',\n",
       " 'wag': 'NOUN',\n",
       " 'together': 'ADV',\n",
       " 'like': 'ADP',\n",
       " 'good': 'ADJ',\n",
       " 'old': 'ADJ',\n",
       " 'days': 'NOUN',\n",
       " 'was': 'VERB',\n",
       " 'chuffed': 'VERB',\n",
       " 'bits': 'NOUN',\n",
       " 'three': 'NUM',\n",
       " 'cram': 'VERB',\n",
       " 'crikey': 'ADJ',\n",
       " 'have': 'VERB',\n",
       " 'spent': 'VERB',\n",
       " 'of': 'ADP',\n",
       " 'our': 'PRON',\n",
       " 'savings': 'NOUN',\n",
       " 'stop': 'VERB',\n",
       " 'faffing': 'VERB',\n",
       " 'around': 'ADV',\n",
       " '’re': 'VERB',\n",
       " 'going': 'VERB',\n",
       " 'be': 'VERB',\n",
       " 'late': 'ADJ',\n",
       " 'managed': 'VERB',\n",
       " 'flog': 'VERB',\n",
       " 'my': 'PRON',\n",
       " 'car': 'NOUN',\n",
       " 'really': 'ADV',\n",
       " 'price': 'NOUN',\n",
       " 'been': 'VERB',\n",
       " 'ill': 'ADJ',\n",
       " 'past': 'ADJ',\n",
       " 'fortnight': 'NOUN',\n",
       " 'n’t': 'ADV',\n",
       " 'recovered': 'VERB',\n",
       " 'thought': 'VERB',\n",
       " 'fail': 'VERB',\n",
       " '’m': 'UH',\n",
       " 'completely': 'ADV',\n",
       " 'gobsmacked': 'ADJ',\n",
       " 'so': 'ADV',\n",
       " 'gutted': 'ADJ',\n",
       " 'driving': 'NOUN',\n",
       " 'again': 'ADV',\n",
       " 'should': 'VERB',\n",
       " 'jolly': 'ADV',\n",
       " 'well': 'UH',\n",
       " 'think': 'VERB',\n",
       " 'telling': 'VERB',\n",
       " 'porkies': 'NOUN',\n",
       " 'do': 'VERB',\n",
       " 'stroppy': 'ADJ',\n",
       " 'eat': 'VERB',\n",
       " 'dinner': 'NOUN',\n",
       " 'table': 'NOUN',\n",
       " 'wonky': 'ADJ',\n",
       " 'made': 'VERB',\n",
       " 'perfect': 'ADJ',\n",
       " 'internest': 'NOUN',\n",
       " 'balcony': 'NOUN',\n",
       " 'no': 'DET',\n",
       " 'way': 'NOUN',\n",
       " 'zumpеd': 'VERB',\n",
       " 'am': 'VERB',\n",
       " 'wearing': 'VERB',\n",
       " 'shirt': 'NOUN',\n",
       " 'as': 'ADP',\n",
       " 'upperwear': 'NOUN',\n",
       " 'while': 'ADP',\n",
       " 'same': 'ADJ',\n",
       " 'sitting': 'VERB',\n",
       " 'in': 'ADP',\n",
       " 'jogging': 'VERB',\n",
       " 'pants': 'NOUN',\n",
       " 'their': 'PRON',\n",
       " 'goalkeeper': 'NOUN',\n",
       " 'slaying': 'VERB'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_flair "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK  очень странно справляется с определением частей речи, потому что он анализирует каждое слово, и если, например, это скоращение, то он его не анализирует. SpaCy и Flair все размечают, но с незнакомыми словами иногда не справляются."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчет аccuracy ниже: сначала для русского, потом для английского."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def items(x,y):\n",
    "    shared_items = {k: x[k] for k in x if k in y and x[k] == y[k]}\n",
    "    return shared_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(g,n):\n",
    "    acc = g/n\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_pymorphy = accuracy (len(items(parse_pymorphy_dict,words)),len(words))\n",
    "accuracy_mystem = accuracy (len(items(parse_mystem_dict,words)),len(words))\n",
    "accuracy_natasha = accuracy (len(items(parse_natasha,words)),len(words))\n",
    "accuracy_nltk = accuracy (len(items(parse_nltk,words_english)),len(words_english))\n",
    "accuracy_spacy = accuracy (len(items(parse_spacy_dict,words_english)),len(words_english))\n",
    "accuracy_flair = accuracy (len(items(parse_flair,words_english)),len(words_english))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8074074074074075"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_pymorphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8222222222222222"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6962962962962963"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7622377622377622"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8741258741258742"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_flair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С русским лучше всего справляется mystem, поэтому по нему и нужно писать функцию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следуюзий код я пыталась запихнуть в функцию, но она не сработала, поэтому я решила все отдельно, да и всего 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem_values = parse_mystem_dict.values()\n",
    "mystem_keys = parse_mystem_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connection(mystem_values, mystem_keys, part_1, part_2):\n",
    "    data = []\n",
    "    x = 0\n",
    "    while x < len(list(mystem_values)):\n",
    "        if list(mystem_values)[x] == part_1:\n",
    "            l = x\n",
    "            m = l + 1\n",
    "            if list(mystem_values)[m] == part_2:\n",
    "                v = list(mystem_values).index(list(mystem_values)[m])\n",
    "                data.append(list(mystem_keys)[l])\n",
    "                data.append(list(mystem_keys)[m])\n",
    "        x += 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_noun = connection(mystem_values=mystem_values, mystem_keys=mystem_keys, part_1='ADJ', part_2='NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['прошлый',\n",
       " 'уикэнд',\n",
       " 'новый',\n",
       " 'телик',\n",
       " 'весь',\n",
       " 'дом',\n",
       " 'недавних',\n",
       " 'пор',\n",
       " 'мой',\n",
       " 'бро',\n",
       " 'мои',\n",
       " 'друзья',\n",
       " 'сасной',\n",
       " 'тянкой',\n",
       " 'бомбезными',\n",
       " 'ичиги',\n",
       " 'какого-то',\n",
       " 'коуча',\n",
       " 'их',\n",
       " 'затроллил',\n",
       " 'паленые',\n",
       " 'сникеры',\n",
       " 'моих',\n",
       " 'друзей',\n",
       " 'вся',\n",
       " 'обувь',\n",
       " 'галимая',\n",
       " 'паль',\n",
       " 'один',\n",
       " 'чувак',\n",
       " 'свой',\n",
       " 'спич',\n",
       " 'моему',\n",
       " 'корешу']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_adv = connection(mystem_values=mystem_values, mystem_keys=mystem_keys, part_1='VERB', part_2='ADV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['была', 'настолько', 'было', 'очень', 'выкупаю', 'почему']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "advs = connection(mystem_values=mystem_values, mystem_keys=mystem_keys, part_1='ADV', part_2='ADV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['давно', 'уже']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary(data, speech_part):\n",
    "    dict_data = {}\n",
    "    v = 0\n",
    "    d = 1\n",
    "    data_1 = []\n",
    "    while d < len(data):\n",
    "        f = data[v]+' '+data[d]\n",
    "        data_1.append(f)\n",
    "        dict_data[f] = speech_part\n",
    "        v += 2\n",
    "        d += 2\n",
    "    return dict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_vadv = dictionary(verb_adv,'VADV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'была настолько': 'VADV', 'было очень': 'VADV', 'выкупаю почему': 'VADV'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_vadv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_adad = dictionary(advs,'ADAD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'давно уже': 'ADAD'}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_adad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_adjn = dictionary(adj_noun,'ADJN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'прошлый уикэнд': 'ADJN',\n",
       " 'новый телик': 'ADJN',\n",
       " 'весь дом': 'ADJN',\n",
       " 'недавних пор': 'ADJN',\n",
       " 'мой бро': 'ADJN',\n",
       " 'мои друзья': 'ADJN',\n",
       " 'сасной тянкой': 'ADJN',\n",
       " 'бомбезными ичиги': 'ADJN',\n",
       " 'какого-то коуча': 'ADJN',\n",
       " 'их затроллил': 'ADJN',\n",
       " 'паленые сникеры': 'ADJN',\n",
       " 'моих друзей': 'ADJN',\n",
       " 'вся обувь': 'ADJN',\n",
       " 'галимая паль': 'ADJN',\n",
       " 'один чувак': 'ADJN',\n",
       " 'свой спич': 'ADJN',\n",
       " 'моему корешу': 'ADJN'}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_adjn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы выделили 3 вида синтаксических групп. Есть ошибки, но это поскольку мы брали данные из словаря майстема, где майстем ошибся. Я выделила эти группы, поскольку прилагательное + существительное - одно из самых частотных словосочетаний, так же как и глагол + наречие(если брать большой текст). Наречие + наречие взяла, потому что такое, наоборот, нечасто встречается, и можно выделить какие-то редкие (опять же если анализировать большой текст). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      ┌► прошлый    amod\n",
      "┌─┌───┌───┌─┌─────────┌─┌─┌──────►┌─┌─└─ уикэнд     amod\n",
      "│ │   │   │ │       ┌►│ │ │       │ │    ,          punct\n",
      "│ │   │   │ │       │ │ │ │       │ │ ┌► новый      amod\n",
      "│ │   │   │ │       │ │ │ │       │ └►└─ телик      conj\n",
      "│ │   │   │ │       │ │ │ │     ┌►│      ,          punct\n",
      "│ │   │   │ │       │ │ │ │     │ │   ┌► весь       det\n",
      "│ │   │   │ │       │ │ │ │     │ └──►└─ дом        conj\n",
      "│ │   │   │ │       │ │ │ │   ┌►│        ,          punct\n",
      "│ │   │ ┌►│ │       │ │ │ │   │ │        недавних   amod\n",
      "│ │ ┌─│ │ │ │       │ │ │ │ ┌►│ │        пор        obl\n",
      "│ │ │ │ │ │ │       │ │ │ │ │ │ │     ┌► ,          punct\n",
      "│ │ │ │ │ │ │       │ │ │ │ │ │ │ ┌──►│  мой        det\n",
      "│ │ │ │ │ │ │       │ │ └►└─│ │ └─│   └─ бро        conj\n",
      "│ │ │ │ │ │ │       │ │     │ │   │ ┌──► ,          punct\n",
      "│ │ │ │ │ │ │       │ │     │ │   │ │ ┌► мои        det\n",
      "│ │ │ │ │ │ │   ┌─┌─│ └────►│ │   └─└─└─ друзья     conj\n",
      "│ │ │ │ │ │ │   │ │ │       │ │       ┌► ,          punct\n",
      "│ │ │ │ │ │ │ ┌─│ │ └─┌────►│ └─────┌─└─ сасной     amod\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ ┌──►│       │    тянкой     conj\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │   │       └──► ,          punct\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │   └───┌──────► бомбезными acl\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │   │   │ ┌────► ичиги      conj\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │   │   │ │ ┌──► ,          punct\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │   │   │ │ │ ┌► какого-то  det\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │   │ ┌►└─└─└─└─ коуча      conj\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ ┌►│ │          ,          punct\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │       ┌► их         nmod\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │     ┌►└─ затроллил  conj\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │ └►│     │    ,          punct\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │   │     │ ┌► паленые    amod\n",
      "│ │ │ │ │ │ │ │ │ │ └►└─└─│   └─────└─└─ сникеры    obj\n",
      "│ │ │ │ │ │ │ │ │ │     │ │         ┌──► ,          punct\n",
      "│ │ │ │ │ │ │ │ │ │     │ │         │ ┌► моих       det\n",
      "│ │ │ │ │ │ └►│ │ │     │ └───────┌─└─└─ друзей     conj\n",
      "│ │ │ │ │ │   │ │ └────►│         │      ,          punct\n",
      "│ │ │ │ │ │   │ │       │         │   ┌► вся        det\n",
      "│ │ │ │ │ └──►│ │       │         │   └─ обувь      conj\n",
      "│ │ │ │ │     │ │       │         └────► ,          punct\n",
      "│ │ │ │ │     │ │       └──────────────► галимая    amod\n",
      "│ │ │ └►│     │ │                        паль       conj\n",
      "│ │ │   │     │ │                     ┌► ,          punct\n",
      "│ │ │   │     │ └────────────────────►│  один       nummod\n",
      "│ └►│   │     │                       └─ чувак      conj\n",
      "│   │   │     │                       └► ,          punct\n",
      "│   │   │     │                       ┌► свой       det\n",
      "└──►│   └─────│                       └─ спич       conj\n",
      "    │         └────────────────────────► ,          punct\n",
      "    │                                 ┌► моему      det\n",
      "    └────────────────────────────────►└─ корешу     acl\n"
     ]
    }
   ],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    \n",
    "    PER,\n",
    "    NamesExtractor,\n",
    "\n",
    "    Doc\n",
    ")\n",
    "segmenter = Segmenter()\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "syntax_parser = NewsSyntaxParser(emb)\n",
    "ner_tagger = NewsNERTagger(emb)\n",
    "morph_vocab = MorphVocab()\n",
    "doc = Doc(','.join(list(dict_adjn.keys())))\n",
    "doc.segment(segmenter)\n",
    "doc.tag_morph(morph_tagger)\n",
    "for token in doc.tokens:\n",
    "    token.lemmatize(morph_vocab)\n",
    "doc.parse_syntax(syntax_parser)\n",
    "doc.sents[0].syntax.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ┌► была      cop\n",
      "┌───┌─┌─└─ настолько \n",
      "│ ┌►│ │    ,         punct\n",
      "│ │ │ └──► было      cop\n",
      "│ │ └────► очень     advmod\n",
      "│ │     ┌► ,         punct\n",
      "└►└───┌─└─ выкупаю   advcl\n",
      "      └──► почему    advmod\n"
     ]
    }
   ],
   "source": [
    "doc = Doc(','.join(list(dict_vadv.keys())))\n",
    "doc.segment(segmenter)\n",
    "doc.tag_morph(morph_tagger)\n",
    "for token in doc.tokens:\n",
    "    token.lemmatize(morph_vocab)\n",
    "doc.parse_syntax(syntax_parser)\n",
    "doc.sents[0].syntax.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Прошлый уикэнд мы чиллили с корешами и хорошо погамали. Сосед купил новый телик, поэтому музон орал на весь дом. С недавних пор мой бро работает ментом и ездит на работу на велике. Туса была настолько крейзи, что мои друзья офигели. Мы будто тусовались в девяностых. Я просрал раффл и завафлил познакомиться с сасной тянкой. Аутфиты были бомбезными: ичиги, багги, дебри, мартинсы. Потом мои братки поехали в бутик, но там было очень дорого, и они погуглили в инете и надыбали аутлет. Там они нашли какого-то коуча, который по фану их затроллил и предложил купить паленые сникеры. Я решил закрыть глаза на понты моих друзей, но они знатно до меня докапались. Не выкупаю, почему они все время надо мной рофлят. В итоге я не сдержался и сказал, что вся их обувь это галимая паль и они не имеют права называть себя сникерхэдами и хайпить на этом. Один чувак сказал, что они отвечают за свой спич. Но я давно уже выкупил, что моему корешу достается все по блату. Энивей, пати у нас прошла отстойно, мне обломали весь кайф.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ┌► Прошлый  amod\n",
      "      ┌►└─ уикэнд   nsubj\n",
      "      │ ┌► мы       nsubj\n",
      "┌─┌─┌─└─└─ чиллили  \n",
      "│ │ │   ┌► с        case\n",
      "│ │ └──►└─ корешами obl\n",
      "│ │   ┌──► и        cc\n",
      "│ │   │ ┌► хорошо   advmod\n",
      "│ └──►└─└─ погамали conj\n",
      "└────────► .        punct\n",
      "        ┌► Сосед   nsubj\n",
      "┌─┌───┌─└─ купил   \n",
      "│ │   │ ┌► новый   amod\n",
      "│ │   └►└─ телик   obj\n",
      "│ │ ┌────► ,       punct\n",
      "│ │ │ ┌──► поэтому advmod\n",
      "│ │ │ │ ┌► музон   nsubj\n",
      "│ └►└─└─└─ орал    conj\n",
      "│ │   ┌──► на      case\n",
      "│ │   │ ┌► весь    det\n",
      "│ └──►└─└─ дом     obl\n",
      "└────────► .       punct\n",
      "        ┌──► С        case\n",
      "        │ ┌► недавних amod\n",
      "      ┌►└─└─ пор      obl\n",
      "      │   ┌► мой      det\n",
      "      │ ┌►└─ бро      nsubj\n",
      "┌───┌─└─└─┌─ работает \n",
      "│   │     └► ментом   xcomp\n",
      "│   │     ┌► и        cc\n",
      "│ ┌─└──►┌─└─ ездит    conj\n",
      "│ │     │ ┌► на       case\n",
      "│ │     └►└─ работу   obl\n",
      "│ │       ┌► на       case\n",
      "│ └──────►└─ велике   obl\n",
      "└──────────► .        punct\n",
      "      ┌────► Туса      nsubj\n",
      "      │ ┌──► была      cop\n",
      "  ┌───│ │ ┌► настолько advmod\n",
      "┌─│   └─└─└─ крейзи    \n",
      "│ │ ┌──────► ,         punct\n",
      "│ │ │ ┌────► что       mark\n",
      "│ │ │ │   ┌► мои       det\n",
      "│ │ │ │ ┌►└─ друзья    nsubj\n",
      "│ └►└─└─└─── офигели   advcl\n",
      "└──────────► .         punct\n"
     ]
    }
   ],
   "source": [
    "doc = Doc(text)\n",
    "doc.segment(segmenter)\n",
    "doc.tag_morph(morph_tagger)\n",
    "for token in doc.tokens:\n",
    "    token.lemmatize(morph_vocab)\n",
    "doc.parse_syntax(syntax_parser)\n",
    "\n",
    "doc.sents[0].syntax.print()\n",
    "doc.sents[1].syntax.print()\n",
    "doc.sents[2].syntax.print()\n",
    "doc.sents[3].syntax.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Программа, которая определяет положительный или отрицательный отзыв."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib.request \n",
    "import collections\n",
    "from collections import Counter\n",
    "from pymystem3 import Mystem\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "import pymorphy2\n",
    "url = 'https://www.kinopoisk.ru/film/1236063/reviews/?status=good&ord=date&rnd=1602064565'\n",
    "req = urllib.request.Request('https://www.kinopoisk.ru/film/1236063/reviews/ord/date/status/good/perpage/50/') \n",
    "response = urllib.request.urlopen(req) \n",
    "html_content_positive = response.read().decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = urllib.request.Request('https://www.kinopoisk.ru/film/1236063/reviews/?status=bad&ord=date&rnd=1602073722&perpage=50') \n",
    "response = urllib.request.urlopen(req) \n",
    "html_content_negative = response.read().decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_positive = BeautifulSoup(html_content_positive, 'html.parser')\n",
    "soup_negative = BeautifulSoup(html_content_negative, 'html.parser')\n",
    "reviews_positive = soup_positive.find_all(class_='_reachbanner_')\n",
    "reviews_negative = soup_negative.find_all(class_='_reachbanner_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reviews_clean(reviews):\n",
    "    reviews_clean = []\n",
    "    for review in reviews:\n",
    "        reviews_clean.append(review.find_all(text=True))\n",
    "    return reviews_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_clean_positive = reviews_clean(reviews_positive)\n",
    "reviews_clean_negative = reviews_clean(reviews_negative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thirty_reviews(review):\n",
    "    thirty_reviews = []\n",
    "    k = 0\n",
    "    while k != 40:\n",
    "        thirty_reviews.append(review[k])\n",
    "        k += 1\n",
    "    \n",
    "    return thirty_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirty_positive_reviews = thirty_reviews(reviews_clean_positive)\n",
    "thirty_negative_reviews = thirty_reviews(reviews_clean_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_reviews = []\n",
    "k = 1\n",
    "while k != 6:\n",
    "    ten_reviews.append(reviews_clean_positive[-k])\n",
    "    ten_reviews.append(reviews_clean_negative[-k])\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def words(reviews):\n",
    "    sentences = []\n",
    "    for review in reviews: \n",
    "        myString = ' '.join(review)\n",
    "        sentence = nltk.sent_tokenize(myString)\n",
    "        sentences.append(sentence)\n",
    "    clean_words = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        for sen in sentence:\n",
    "            words = nltk.word_tokenize(sen)\n",
    "            clean_words.append(words)\n",
    "    return clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_from_positive = words(thirty_positive_reviews)\n",
    "words_from_negative = words(thirty_negative_reviews)\n",
    "words_from_ten = words(ten_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lists(words):\n",
    "    words_new=[]\n",
    "    for lst in words:\n",
    "        for el in lst:\n",
    "            words_new.append(el)\n",
    "    return words_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = lists(words_from_positive)\n",
    "negative = lists(words_from_negative)\n",
    "ten = lists(words_from_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_list(words):\n",
    "    import re\n",
    "    for k in words:\n",
    "        if len(k) < 2:\n",
    "            words.remove(k)\n",
    "        k = k.replace(\"-\", \"\")\n",
    "        re.sub(r\"\\d+\", \"\", k, flags=re.UNICODE)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_positive = clean_list(positive)\n",
    "clean_negative = clean_list(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_lower_tag(words):\n",
    "    tokens = []\n",
    "    for i in words:\n",
    "        tokens.append(i.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_positive = token_lower_tag(clean_positive)\n",
    "lower_negative = token_lower_tag(clean_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmas(rev):\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    new = []\n",
    "    for word in rev:\n",
    "        p = morph.parse(word)[0]\n",
    "        new.append(p.normal_form)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_positive = lemmas(lower_positive)\n",
    "lemmas_negative = lemmas(lower_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "def delete_stopwords(review_1,stopwords):\n",
    "    result=list(set(review_1) ^ set(stopwords))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_positive = delete_stopwords(lemmas_positive,russian_stopwords)\n",
    "new_negative = delete_stopwords(lemmas_negative,russian_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "couner_positive = Counter(new_positive)\n",
    "couner_negative = Counter(new_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_positive = [k[0] for k in couner_positive.most_common(100)]\n",
    "most_common_negative = [k[0] for k in couner_negative.most_common(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in most_common_positive:\n",
    "    for l in most_common_negative:\n",
    "        if k == l:\n",
    "            most_common_positive.remove(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in most_common_negative:\n",
    "    for l in most_common_positive:\n",
    "        if k == l:\n",
    "            most_common_negative.remove(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm_review(your_review):\n",
    "    from pymystem3 import Mystem\n",
    "    m = Mystem()\n",
    "    new = ''.join(your_review)\n",
    "    lemmas = m.lemmatize(new)\n",
    "    for k in lemmas:\n",
    "        if len(k) < 3:\n",
    "            lemmas.remove(k)\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def che_review(your_review):\n",
    "    x = 0\n",
    "    c = 0\n",
    "    for word in your_review:\n",
    "        if word in most_common_positive:\n",
    "            x +=1\n",
    "        elif word in most_common_negative:\n",
    "            c +=1\n",
    "        else:\n",
    "            pass\n",
    "    if x > c:\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "che_review(lemm_review(ten_reviews[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Улучшения:\n",
    "1) Увеличить выборку отзывов, чтобы получить больше данных для анализа\n",
    "2) Использовать дополнительные фичи: например, word2vec или какие-то другие nlp-модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
